{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Multiple Hypothesis Testing\n",
    "Welcome to the first DS102 lab! \n",
    "\n",
    "The goals of this lab are to get familiar with multiple hypothesis testing scenarios, as well as to investigate several procedures for controlling the number of false discoveries.\n",
    "\n",
    "The code you need to write is commented out with a message \"TODO: fill in\". There is additional documentation for each part as you go along.\n",
    "\n",
    "\n",
    "## Course Policies\n",
    "\n",
    "**Collaboration Policy**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** in the cell below.\n",
    "\n",
    "**Submission**: to submit this assignment, rerun the notebook from scratch (by selecting Kernel > Restart & Run all), and then print as a pdf (File > download as > pdf) and submit it to Gradescope.\n",
    "\n",
    "\n",
    "**This assignment should be completed and submitted before Monday September 16, 2019 at 11:59 PM.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborators\n",
    "Write names of your collaborators in this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Let's begin by importing the libraries we will use. You can find the documentation for the libraries here:\n",
    "* matplotlib: https://matplotlib.org/3.1.1/contents.html\n",
    "* numpy: https://docs.scipy.org/doc/\n",
    "* pandas: https://pandas.pydata.org/pandas-docs/stable/\n",
    "* seaborn: https://seaborn.pydata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Distribution of p-values under the null and alternative hypotheses\n",
    "\n",
    "The first part of this assignment looks at the distribution of p-values. We will define a null distribution as normally distribution with mean $1$ and variance $1$. First, we will draw 1000 instances from this distribution, and invstigate the distribution of p-values that result from a Z-test on these scores. Then, in part b, we will repeat the same procedure, but for data drawn from an alternative distribution. In part c you will summarize your findings.\n",
    "\n",
    "We'll consider draws from the null distribution:\n",
    "$$ D_0: \\mathcal{N}(0,1)$$\n",
    "as well as from an alternative distribution:\n",
    "$$ D_1: \\mathcal{N}(2,1)$$\n",
    "In part (2), we'll disambiguate whether the random draws we see are generated from $D_0$ or $D_1$, using the p-values of each draw. Specifically, we'll use p-values from a one-sided test, such that the p-value of an observed value $x_i$ is the probability that a random value $x'$ drawn from $D_0$ has a value equal or larger to $x_i$the that value:\n",
    "$$ P(x' \\geq x_i \\, |\\, x' \\sim D_0)$$\n",
    "\n",
    "\n",
    "The following function will calculate the p-values for you, when you provide the mean and standard deviation of the null distribution. All you need to do there is run the cell so it gets intstanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is written written for you, we'll use one-sided hypothesis tests\n",
    "def calculate_p_values(x, mean_0, stdev_0):\n",
    "    # for a one sided test, with h_1: mu > mean_0\n",
    "    z_scores = (x - mean_0)/stdev_0\n",
    "    return 1 - scipy.stats.norm.cdf(z_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part (1), we investigate the distribution of p-values for draws from the null distribution and from the alternative distribuation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a) plot the distribution of p-values for 1000 random draws that actually come from the null distribution: \n",
    " $$ x_i \\sim \\mathcal{N}(0, 1) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate n draws from the normal distribution with mean mu_0 and variance sigma_0 = 1\n",
    "mu_a = 0\n",
    "sigma_a = 1\n",
    "n = 1000\n",
    "\n",
    "# define the random state\n",
    "rs = np.random.RandomState(0)\n",
    "\n",
    "# x_a is an n-dimensional vector with each draw equal to x_i defined aboce.\n",
    "x_a = sigma_a * rs.randn(n) + mu_a\n",
    "\n",
    "# plot the distribution of p-values for each draw\n",
    "p_values = calculate_p_values(x_a, mean_0=mu_a, stdev_0 = sigma_a)\n",
    "\n",
    "sns.distplot(p_values, kde=False)\n",
    "\n",
    "# TODO: fill in axes labels\n",
    "plt.xlabel(\"TODO: fill in axis label\")\n",
    "plt.ylabel(\"TODO: fill in axis label\")\n",
    "plt.title(\"distribution of p-values for data drawn from the null distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b) plot the distribution of p-values for 1000 random draws that actually from an alternative distribution:\n",
    " $$ x_i \\sim \\mathcal{N}(2, 1) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw for a different distribution\n",
    "mu_b = 2\n",
    "sigma_b = 1\n",
    "n = 1000\n",
    "rs = np.random.RandomState(0)\n",
    "\n",
    "# x in an n_0-dimensional vector\n",
    "x_b = sigma_b * rs.randn(n) + mu_b\n",
    "\n",
    "# plot the distribution of p-values for each draw (recall that H_0 is defined by N(0,1))\n",
    "p_values_b = # TODO: fill in\n",
    "\n",
    "sns.distplot(p_values_b, kde=False)\n",
    "plt.xlabel(\"TODO: fill in\")\n",
    "plt.ylabel(\"TODO: fill in\")\n",
    "plt.title(\"distribution of p-values for data drawn from the alternative distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c) What do you notice?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: fill in (<=2 sentences) of your observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the decision-making setting, all see is the combined distribution for draws from (0) and from (1), but not their designated labels. In what follows we will look at different methods for trying to match instances from (1) to declared \"discoveries\" using the p-values. As the histogram of p-values above shows, there will in general be mistakes. We would like to specifically control the number of false discoveries reported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Procedures to control False Discovery\n",
    "\n",
    "This question looks at controlling the probability of false discoveries in a decision-making process for multiple hypothesis testing. In particular, we will implement three methods for making discoveries,\n",
    "    1. naive p-values (ignoring that multiple testing is happening)\n",
    "    2. Bonferroni-corrected  p-values to account for multiple testing\n",
    "    3. The Benjamini-Hochberg procdure for multiple testing\n",
    "    \n",
    "    \n",
    "For each method, we will assess the decisions made on a simulated data set. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: you just need to run this cell to instantiate variables; don't change this code.\n",
    "\n",
    "rs = np.random.RandomState(0)\n",
    "n = 1000\n",
    "\n",
    "# roughly 90% of the data comes from the null distirubtion, \n",
    "true_values = rs.binomial(1, 0.2, 1000) \n",
    "# null distribution is N(0,1) and alternative distribution is N(2,1)\n",
    "x_obs= rs.randn(n) + 2 * true_values\n",
    "\n",
    "plt.figure()\n",
    "sns.distplot(x_obs[true_values == 0],  label=\"draws from null (0) distribution\", kde=False)\n",
    "sns.distplot(x_obs[true_values == 1],  label=\"daws from alt. (1) distribution\", kde=False)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.title(\"data distributions\")\n",
    "plt.legend(bbox_to_anchor=(1,1))\n",
    "\n",
    "# NOTE: you just need to run this cell and understand what it does; no code to modify or write here. \n",
    "# set alpha \n",
    "alpha = 0.05\n",
    "\n",
    "# calculate the p-values for each individual hypothesis\n",
    "p_values = calculate_p_values(x_obs, mean_0=0, stdev_0 = 1)\n",
    "\n",
    "plt.figure()\n",
    "bins = np.linspace(0,1,num=20)\n",
    "sns.distplot(p_values[true_values == 0],  label=\"draws from null (0) distribution\", kde=False, bins=bins)\n",
    "sns.distplot(p_values[true_values == 1],  label=\"daws from alt. (1) distribution\", kde=False,bins=bins)\n",
    "plt.legend(bbox_to_anchor=(1,1))\n",
    "plt.xlabel(\"p-value\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.title(\"p-value distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a) Fill in the following functions regarding confusion matrices.\n",
    "\n",
    "These functions will be important for reporting your results in a standardized way; later code assumes that you have implemented them so please do start here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_results(predicted_discoveries, truth):\n",
    "    # input: predicted discoveries: n-dimensional array of 0/1 values where 1 indicates a \"discovery\"\n",
    "    #        truth: n-dimensional array of 0/1 values where 1 indicates a draw from the altertanative\n",
    "    \n",
    "    # populate the following dictionary with COUNTS:\n",
    "    # TODO: fill in each of these counts\n",
    "    TP_count = # TODO: fill in\n",
    "    TN_count = # TODO: fill in\n",
    "    FP_count = # TODO: fill in\n",
    "    FN_count = # TODO: fill in\n",
    "    \n",
    "    results_dictionary = {\"TN_count\": TN_count,\n",
    "                          \"TP_count\": TP_count,\n",
    "                          \"FN_count\": FN_count,\n",
    "                          \"FP_count\": FP_count,\n",
    "                         }\n",
    "    \n",
    "    # this function is defined for you below; this will make your life easier in a few steps.\n",
    "    print_confusion_matrix(results_dictionary)\n",
    "    return results_dictionary\n",
    "\n",
    "def print_false_discovery_fraction(results_dictionary):\n",
    "    # the results_dictionary object is defined via the output of report_results()\n",
    "    \n",
    "    # TODO: fill in - compute the false discovery fraction from the results dictionary\n",
    "    total_predicted_discoveries = # TODO: fill in\n",
    "    false_discovery_frac = # TODO: fill in\n",
    "    \n",
    "    # leave this printing functions as they are; you will need them later\n",
    "    print(\"total discoveries: {0}\".format(total_predicted_discoveries))\n",
    "    print(\"fraction of discoveries which were actually false: {0:.3f}\".format(false_discovery_frac))\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "def print_confusion_matrix(res_dict):\n",
    "    # This is a helper function to print the confusion matrix. You don't need to modify this code.\n",
    "    results_df = pd.DataFrame(data = {\"Decision = 0\": [res_dict['TN_count'], res_dict['FN_count']], \n",
    "                                      \"Decision = 1\":  [res_dict['FP_count'], res_dict['TP_count']]},\n",
    "                             index=[\"Truth = 0\", \"Truth = 1\"])\n",
    "    print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2b) Naive thresholding\n",
    "Here we will investigate the result of using the threshold $\\alpha = 0.05$ to test each hypothesis independently, ignoring that we are in a multiple testing scenario. \n",
    "\n",
    "Fill in the code for the function below to test each hypothesis at significance level $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_alpha_threshold(p_values, alpha):\n",
    "    # returns decisions: a binary vector of the same length as p-values, \n",
    "    # where decisions[i] is 1 if p_values[i] is deemed significant at level alpha, and 0 otherwize\n",
    "    \n",
    "    # TODO: fill in\n",
    "    decisions = #\n",
    "    return decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you've filled in naive_alpha_threshold(),  run this cell to print the results. \n",
    "naive_decisions = naive_alpha_threshold(p_values, alpha)\n",
    "\n",
    "results = report_results(naive_decisions,true_values)\n",
    "print()\n",
    "print_false_discovery_fraction(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2c) Bonferroni\n",
    "Here we will investigate the result of using Bonferroni-corrected p-values to declare discoveries.\n",
    "First, implement the Bonfreroni procedure in the function below. \n",
    "\n",
    "Recall that for testing $n$ hypotheses with total signifcance $\\alpha$, the resulting procedure is to test each hypothesis with significance $\\frac{\\alpha}{n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bonferroni(p_values, alpha_tot):\n",
    "    # returns the decisions made from the bonferroni correction procedure\n",
    "    \n",
    "    # TODO: fill in\n",
    "    decisions = #\n",
    "    \n",
    "    return decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you've filled in bonferroni(), just run this cell to print the results. \n",
    "bonferroni_decisions = bonferroni(p_values, alpha)\n",
    "\n",
    "results = report_results(bonferroni_decisions,true_values)\n",
    "print()\n",
    "print_false_discovery_fraction(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2d) Benjamini-Hochberg\n",
    "Now we will investigate the result of implementing Benjamini-Hochberg procedure for multiple hypothesis testing.\n",
    "First, implement the Benjamini-Hochberg procedure in the function below. \n",
    "\n",
    "Recall that for testing $n$ hypotheses with total signifcance $\\alpha$, the resulting procedure is to find the largest $k$ such that the $k^{th}$-largest of the n p-values is less than or equal to $k \\frac{\\alpha}{n}$:\n",
    "$$ P_{(k)} \\leq k \\frac{\\alpha}{n}$$\n",
    "We then declare a discovery for all p-values with lesser or equal value to this $k^{th}$ p-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def benjamini_hochberg(p_values, alpha):\n",
    "    # returns decisions: a binary vector of the same length as p-values, \n",
    "    # where decisions[i] is 1 if p_values[i] is deemed significant at level alpha, and 0 otherwize\n",
    "    \n",
    "    # TODO: fill in\n",
    "    decisions = #\n",
    "    \n",
    "    return decisions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, asses the result of applying the Benjamini Hochberg procedure to the simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you've filled in benjamini_hochberg(), just run this cell to print the results.\n",
    "bh_decisions = benjamini_hochberg(p_values, alpha)\n",
    "\n",
    "bh_results = report_results(bh_decisions,true_values)\n",
    "print()\n",
    "\n",
    "print_false_discovery_fraction(bh_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2e) Conclusions\n",
    "\n",
    "Finally, write a short (<= 4 sentences) summary comparing the three different methods from this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: fill in your comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final tests\n",
    "If all the tests below pass you can assume you have successfuly completed the testable parts of the lab. Don't worry about understanding the code below, you just need to make sure no asserts fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import sys\n",
    "\n",
    "def assert_discoveries(results,\n",
    "                       true_vales,\n",
    "                       true_positives_hash,\n",
    "                       false_positives_hash,\n",
    "                       true_negatives_hash,\n",
    "                       false_negatives_hash,\n",
    "                       false_discovery_frac_hash):\n",
    "    def get_hash(num):\n",
    "        return hashlib.md5(str(num).encode()).hexdigest()\n",
    "    res_dict = report_results(results, true_values)\n",
    "    assert(get_hash(res_dict['TP_count']) == true_positives_hash)\n",
    "    assert(get_hash(res_dict['FP_count']) == false_positives_hash)\n",
    "    assert(get_hash(res_dict['TN_count']) == true_negatives_hash)\n",
    "    assert(get_hash(res_dict['FN_count']) == false_negatives_hash)\n",
    "    _, false_discovery_frac = print_false_discovery_fraction(res_dict)\n",
    "    print(false_discovery_frac)\n",
    "    print(get_hash(false_discovery_frac))\n",
    "    assert(get_hash(false_discovery_frac) == false_discovery_frac_hash)\n",
    "\n",
    "\n",
    "assert_discoveries(naive_decisions,\n",
    "                   true_values,\n",
    "                   true_positives_hash=\"9b8619251a19057cff70779273e95aa6\",\n",
    "                   false_positives_hash=\"a1d0c6e83f027327d8461063f4ac58a6\",\n",
    "                   true_negatives_hash=\"ccb0989662211f61edae2e26d58ea92f\",\n",
    "                    false_negatives_hash=\"d2ddea18f00665ce8623e36bd4e3c7c5\",\n",
    "                   false_discovery_frac_hash=\"925c6c13fdd65415e416ddf203c36673\")\n",
    "assert_discoveries(bonferroni_decisions,\n",
    "                   true_values,\n",
    "                   true_positives_hash=\"1679091c5a880faf6fb5e6087eb1b2dc\",\n",
    "                   false_positives_hash=\"cfcd208495d565ef66e7dff9f98764da\",\n",
    "                   true_negatives_hash=\"beb22fb694d513edcf5533cf006dfeae\",\n",
    "                   false_negatives_hash=\"85d8ce590ad8981ca2c8286f79f59954\",\n",
    "                   false_discovery_frac_hash=\"30565a8911a6bb487e3745c0ea3c8224\")\n",
    "assert_discoveries(bh_decisions,\n",
    "                   true_values,\n",
    "                   true_positives_hash=\"642e92efb79421734881b53e1e1b18b6\",\n",
    "                   false_positives_hash=\"c4ca4238a0b923820dcc509a6f75849b\",\n",
    "                   true_negatives_hash=\"35cf8659cfcb13224cbd47863a34fc58\",\n",
    "                   false_negatives_hash=\"2a79ea27c279e471f4d180b08d62b00a\",\n",
    "                   false_discovery_frac_hash=\"8b3355aee6601d21bc73332df86a3614\")\n",
    "    \n",
    "print(\"All tests passed! You are awesome!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
